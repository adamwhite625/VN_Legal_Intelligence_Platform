from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
from app.core.config import llm

def fallback_node(state):
    """
    Node 6: Xá»­ lÃ½ thÃ´ng minh khi thiáº¿u thÃ´ng tin.
    """
    status = state["check_status"]
    query = state.get("standalone_query", state["query"])
    docs = state["retrieved_docs"]
    
    # TRÆ¯á»œNG Há»¢P A: KhÃ´ng cÃ³ luáº­t (NO_LAW) -> Tá»« chá»‘i tháº³ng thá»«ng (Rule cá»©ng)
    if status == "NO_LAW":
        print("ğŸ§  [FALLBACK]: Tá»« chá»‘i vÃ¬ khÃ´ng cÃ³ dá»¯ liá»‡u luáº­t.")
        msg = (
            "Xin lá»—i, hiá»‡n táº¡i cÆ¡ sá»Ÿ dá»¯ liá»‡u cá»§a tÃ´i chÆ°a cÃ³ Ä‘á»§ vÄƒn báº£n phÃ¡p lÃ½ chÃ­nh xÃ¡c Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i nÃ y.\n"
            "Äá»ƒ Ä‘áº£m báº£o an toÃ n phÃ¡p lÃ½, tÃ´i xin phÃ©p khÃ´ng tá»± suy Ä‘oÃ¡n. Báº¡n vui lÃ²ng tham váº¥n luáº­t sÆ° trá»±c tiáº¿p."
        )
        return {"generation": msg, "sources": []}

    # TRÆ¯á»œNG Há»¢P B: CÃ³ luáº­t nhÆ°ng thiáº¿u thÃ´ng tin user (MISSING_INFO) -> Há»i láº¡i (Clarification)
    if status == "MISSING_INFO":
        print("ğŸ§  [FALLBACK]: Äang táº¡o cÃ¢u há»i lÃ m rÃµ (Clarification)...")
        context = "\n".join([f"- {d['content']}" for d in docs])
        
        prompt = PromptTemplate(
            template="""Báº¡n lÃ  Luáº­t sÆ° tÆ° váº¥n.
            Báº¡n Ä‘Ã£ tÃ¬m tháº¥y quy Ä‘á»‹nh phÃ¡p luáº­t liÃªn quan, nhÆ°ng chÆ°a thá»ƒ Ã¡p dá»¥ng chÃ­nh xÃ¡c vÃ¬ ngÆ°á»i há»i cung cáº¥p thiáº¿u thÃ´ng tin chi tiáº¿t.
            
            VÄƒn báº£n luáº­t:
            {context}
            
            CÃ¢u há»i ngÆ°á»i dÃ¢n: {query}
            
            Nhiá»‡m vá»¥:
            HÃ£y viáº¿t cÃ¢u tráº£ lá»i theo cáº¥u trÃºc sau:
            1. Kháº³ng Ä‘á»‹nh: "Váº¥n Ä‘á» nÃ y Ä‘Æ°á»£c quy Ä‘á»‹nh táº¡i [TÃªn luáº­t], tuy nhiÃªn káº¿t quáº£ phá»¥ thuá»™c vÃ o tá»«ng trÆ°á»ng há»£p cá»¥ thá»ƒ."
            2. YÃªu cáº§u: "Äá»ƒ tÃ´i tÆ° váº¥n chÃ­nh xÃ¡c, báº¡n vui lÃ²ng cung cáº¥p thÃªm:"
            3. Liá»‡t kÃª: CÃ¡c gáº¡ch Ä‘áº§u dÃ²ng nhá»¯ng thÃ´ng tin cáº§n thiáº¿t (VÃ­ dá»¥: Äá»™ tuá»•i, loáº¡i há»£p Ä‘á»“ng, thá»i Ä‘iá»ƒm kÃ½ káº¿t...). Dá»±a chÃ­nh xÃ¡c vÃ o cÃ¡c Ä‘iá»u kiá»‡n ghi trong vÄƒn báº£n luáº­t á»Ÿ trÃªn.
            
            Lá»i tÆ° váº¥n:
            """,
            input_variables=["context", "query"]
        )
        
        chain = prompt | llm | StrOutputParser()
        msg = chain.invoke({"context": context, "query": query})
        
        # Váº«n tráº£ vá» nguá»“n Ä‘á»ƒ user tin tÆ°á»Ÿng lÃ  mÃ¬nh cÃ³ cÄƒn cá»©
        sources = list(set([d['source'] for d in docs]))
        return {"generation": msg, "sources": sources}
        
    return {"generation": "Lá»—i xá»­ lÃ½ tráº¡ng thÃ¡i.", "sources": []}