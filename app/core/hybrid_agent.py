import os
from typing import TypedDict, List, Dict, Any

# ----------- LangGraph -----------
from langgraph.graph import StateGraph, END

# ----------- LLM & Embeddings --------
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ----------- Qdrant & Search --------------
from qdrant_client import QdrantClient
from duckduckgo_search import DDGS

# ============================================================
# 1. C·∫§U H√åNH H·ªÜ TH·ªêNG
# ============================================================

embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)

QDRANT_HOST = os.getenv("QDRANT_HOST", "localhost")
QDRANT_PORT = int(os.getenv("QDRANT_PORT", 6333))
COLLECTION_NAME = "law_data" 

client = QdrantClient(host=QDRANT_HOST, port=QDRANT_PORT)

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash", 
    google_api_key=os.getenv("GOOGLE_API_KEY"),
    temperature=0
)

def print_thought(step_name: str, thought: str, color: str = "\033[94m"):
    reset = "\033[0m"
    print(f"\n{color}üß† [{step_name}]: {reset}\n{thought}\n{'-'*50}")

# ============================================================
# 2. ƒê·ªäNH NGHƒ®A STATE (TH√äM standalone_query)
# ============================================================

class LawAgentState(TypedDict):
    query: str                # C√¢u h·ªèi g·ªëc c·ªßa ng∆∞·ªùi d√πng (VD: "N·ªôp ·ªü ƒë√¢u")
    standalone_query: str     # C√¢u h·ªèi ƒë√£ hi·ªÉu ng·ªØ c·∫£nh (VD: "N·ªôp h·ªì s∆° ly h√¥n ·ªü ƒë√¢u")
    intent: str
    search_strategy: dict
    retrieved_docs: List[Dict] 
    is_sufficient: bool
    generation: str
    sources: List[str]
    chat_history: str         # L·ªãch s·ª≠ h·ªôi tho·∫°i

# ============================================================
# 3. C√ÅC NODE X·ª¨ L√ù
# ============================================================

# üü¶ NODE 1: Intent Analysis & Contextualization (N√ÇNG C·∫§P QUAN TR·ªåNG)
def intent_analysis_node(state: LawAgentState) -> LawAgentState:
    query = state["query"]
    history = state.get("chat_history", "")
    
    # B∆∞·ªõc 1: Vi·∫øt l·∫°i c√¢u h·ªèi n·∫øu c·∫ßn (Contextualize)
    if history:
        print_thought("1a. HI·ªÇU NG·ªÆ C·∫¢NH", f"ƒêang xem x√©t l·ªãch s·ª≠ ƒë·ªÉ hi·ªÉu c√¢u h·ªèi: '{query}'")
        rewrite_prompt = PromptTemplate.from_template(
            """B·∫°n l√† chuy√™n gia ng√¥n ng·ªØ.
            Nhi·ªám v·ª•: Vi·∫øt l·∫°i c√¢u h·ªèi m·ªõi nh·∫•t c·ªßa ng∆∞·ªùi d√πng th√†nh m·ªôt c√¢u ƒë·∫ßy ƒë·ªß √Ω nghƒ©a, d·ª±a tr√™n l·ªãch s·ª≠ tr√≤ chuy·ªán.
            
            L·ªãch s·ª≠ tr√≤ chuy·ªán:
            {history}
            
            C√¢u h·ªèi m·ªõi: {query}
            
            Y√™u c·∫ßu:
            - N·∫øu c√¢u h·ªèi m·ªõi thi·∫øu ch·ªß ng·ªØ/v·ªã ng·ªØ (v√≠ d·ª•: "C√≤n ti·ªÅn √°n ph√≠?", "N·ªôp ·ªü ƒë√¢u?"), h√£y gh√©p v·ªõi √Ω c·ªßa c√¢u tr∆∞·ªõc ƒë·ªÉ th√†nh c√¢u ho√†n ch·ªânh.
            - N·∫øu c√¢u h·ªèi ƒë√£ ƒë·∫ßy ƒë·ªß, gi·ªØ nguy√™n.
            - CH·ªà tr·∫£ v·ªÅ c√¢u h·ªèi ƒë√£ vi·∫øt l·∫°i.
            """
        )
        standalone_query = (rewrite_prompt | llm | StrOutputParser()).invoke({"history": history, "query": query}).strip()
        print_thought("1b. C√ÇU H·ªéI ƒê√É HI·ªÇU", f"G·ªëc: '{query}'\nHi·ªÉu l√†: '{standalone_query}'", "\033[96m")
    else:
        standalone_query = query
        print_thought("1b. C√ÇU H·ªéI", f"'{standalone_query}' (Kh√¥ng c√≥ l·ªãch s·ª≠)", "\033[96m")

    # B∆∞·ªõc 2: Ph√¢n t√≠ch Intent d·ª±a tr√™n c√¢u ƒë√£ vi·∫øt l·∫°i
    prompt = PromptTemplate.from_template(
        "Ph√¢n lo·∫°i c√¢u h·ªèi sau: H·ªéI_M·ª®C_PH·∫†T, H·ªéI_TH·ª¶_T·ª§C, QUY·ªÄN_NGHƒ®A_V·ª§, ƒê·ªäNH_NGHƒ®A, KH√îNG_R√ï.\nC√¢u h·ªèi: {q}\nCh·ªâ tr·∫£ v·ªÅ t√™n nh√≥m."
    )
    intent = (prompt | llm | StrOutputParser()).invoke({"q": standalone_query}).strip()
    
    # Strategy
    strategy = {"limit": 3}
    if intent == "H·ªéI_TH·ª¶_T·ª§C": strategy = {"limit": 5}
    elif intent == "KH√îNG_R√ï": strategy = {"limit": 0}
    
    state["standalone_query"] = standalone_query # L∆∞u c√¢u h·ªèi m·ªõi v√†o state
    state["intent"] = intent
    state["search_strategy"] = strategy
    
    print_thought("1c. PH√ÇN T√çCH √ù ƒê·ªäNH", f"Intent: {intent}", "\033[94m")
    return state

# üü¶ NODE 2: Law Retriever (S·ª≠a ƒë·ªÉ d√πng standalone_query)
def law_retriever_node(state: LawAgentState) -> LawAgentState:
    # QUAN TR·ªåNG: T√¨m ki·∫øm b·∫±ng c√¢u h·ªèi ƒê√É HI·ªÇU NG·ªÆ C·∫¢NH, kh√¥ng d√πng c√¢u g·ªëc
    query_to_search = state["standalone_query"] 
    limit = state["search_strategy"].get("limit", 3)
    
    if limit == 0:
        state["retrieved_docs"] = []
        return state

    try:
        vector = embeddings.embed_query(query_to_search)
        try:
            results = client.search(collection_name=COLLECTION_NAME, query_vector=vector, limit=limit)
        except AttributeError:
            results = client.query_points(collection_name=COLLECTION_NAME, query=vector, limit=limit).points
            
        docs = []
        log_titles = []
        for r in results:
            payload = r.payload or {}
            source_title = f"{payload.get('law_name', 'Lu·∫≠t')} {payload.get('law_id', '')}".strip()
            
            docs.append({
                "source": source_title,
                "content": payload.get("content", "")
            })
            log_titles.append(f"- {source_title}")
            
        state["retrieved_docs"] = docs
        print_thought("2. T√åM KI·∫æM VECTOR DB", f"Query: {query_to_search}\nK·∫øt qu·∫£:\n" + "\n".join(log_titles), "\033[92m")
        
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói Qdrant: {e}")
        state["retrieved_docs"] = []
        
    return state

# üü¶ NODE 3: Sufficiency Checker
def sufficiency_checker_node(state: LawAgentState) -> LawAgentState:
    docs = state["retrieved_docs"]
    if not docs:
        state["is_sufficient"] = False
        return state

    context_text = "\n".join([f"{d['source']}: {d['content']}" for d in docs])
    prompt = PromptTemplate.from_template(
        "C√¢u h·ªèi: {query}\nT√†i li·ªáu: {context}\nT√†i li·ªáu c√≥ ƒë·ªß ƒë·ªÉ tr·∫£ l·ªùi kh√¥ng? Tr·∫£ v·ªÅ C√ì ho·∫∑c KH√îNG."
    )
    # Check d·ª±a tr√™n c√¢u h·ªèi ƒë√£ hi·ªÉu ng·ªØ c·∫£nh
    resp = (prompt | llm | StrOutputParser()).invoke({"query": state["standalone_query"], "context": context_text})
    
    is_sufficient = "C√ì" in resp.upper()
    print_thought("3. KI·ªÇM TRA CƒÇN C·ª®", f"ƒê·ªß cƒÉn c·ª©? {is_sufficient}", "\033[93m")
    state["is_sufficient"] = is_sufficient
    return state

# üü¶ NODE 4: Web Search (Fallback)
def web_search_node(state: LawAgentState) -> LawAgentState:
    query = state["standalone_query"] # Search web c≈©ng b·∫±ng c√¢u ƒë·∫ßy ƒë·ªß
    print_thought("4. WEB SEARCH", f"ƒêang t√¨m Google: {query}...", "\033[96m")
    try:
        with DDGS() as ddgs:
            results = list(ddgs.text(query, max_results=3))
            web_docs = []
            for r in results:
                web_docs.append({
                    "source": "Internet",
                    "content": r.get('body', '')
                })
            state["retrieved_docs"] = web_docs
            state["is_sufficient"] = True
    except:
        state["retrieved_docs"] = []
    return state

# üü¶ NODE 5: Answer Generator
def answer_generator_node(state: LawAgentState) -> LawAgentState:
    docs = state["retrieved_docs"]
    # D√πng c√¢u h·ªèi g·ªëc trong prompt tr·∫£ l·ªùi ƒë·ªÉ t·∫°o c·∫£m gi√°c t·ª± nhi√™n, 
    # nh∆∞ng d√πng ng·ªØ c·∫£nh l·ªãch s·ª≠ ƒë·ªÉ AI hi·ªÉu.
    query = state["query"] 
    history = state.get("chat_history", "")
    
    unique_sources = list(set([d["source"] for d in docs]))
    state["sources"] = unique_sources
    
    context = "\n\n".join([f"Ngu·ªìn: {d['source']}\nN·ªôi dung: {d['content']}" for d in docs])
    
    prompt = PromptTemplate.from_template(
        """B·∫°n l√† Lu·∫≠t s∆∞ AI.
        
        L·ªãch s·ª≠ tr√≤ chuy·ªán:
        {history}
        
        Th√¥ng tin ph√°p l√Ω t√¨m ƒë∆∞·ª£c (D·ª±a tr√™n c√¢u h·ªèi ƒë√£ hi·ªÉu √Ω):
        {context}
        
        C√¢u h·ªèi hi·ªán t·∫°i c·ªßa ng∆∞·ªùi d√πng: {query}
        
        Y√™u c·∫ßu: Tr·∫£ l·ªùi t·ª± nhi√™n, ti·∫øp n·ªëi m·∫°ch chuy·ªán. Tr√≠ch d·∫´n lu·∫≠t r√µ r√†ng."""
    )
    answer = (prompt | llm | StrOutputParser()).invoke({
        "history": history, 
        "context": context, 
        "query": query
    })
    
    print_thought("5. T·ªîNG H·ª¢P TR·∫¢ L·ªúI", "ƒê√£ xong.", "\033[95m")
    state["generation"] = answer
    return state

# üü¶ NODE 6: Clarification
def clarification_agent_node(state: LawAgentState) -> LawAgentState:
    state["generation"] = "Xin l·ªói, t√¥i ch∆∞a t√¨m th·∫•y ƒë·ªß cƒÉn c·ª© ph√°p l√Ω ƒë·ªÉ tr·∫£ l·ªùi c√¢u h·ªèi n√†y."
    state["sources"] = []
    return state

# ============================================================
# 4. X√ÇY D·ª∞NG GRAPH
# ============================================================

def route_decision(state: LawAgentState):
    if state["is_sufficient"]: return "generate"
    return "web_search"

workflow = StateGraph(LawAgentState)
workflow.add_node("analyze", intent_analysis_node)
workflow.add_node("retrieve", law_retriever_node)
workflow.add_node("check", sufficiency_checker_node)
workflow.add_node("web_search", web_search_node)
workflow.add_node("generate", answer_generator_node)
workflow.add_node("clarify", clarification_agent_node)

workflow.set_entry_point("analyze")
workflow.add_edge("analyze", "retrieve")
workflow.add_edge("retrieve", "check")

workflow.add_conditional_edges(
    "check",
    route_decision,
    {
        "generate": "generate",
        "web_search": "web_search"
    }
)
workflow.add_edge("web_search", "generate")
workflow.add_edge("generate", END)
workflow.add_edge("clarify", END)

app = workflow.compile()