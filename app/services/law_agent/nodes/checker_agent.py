from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import JsonOutputParser
from app.core.config import llm

# Äá»‹nh nghÄ©a cáº¥u trÃºc JSON Ä‘áº§u ra
# (Máº¹o: Äá»‹nh nghÄ©a class Pydantic Ä‘á»ƒ parser chÃ­nh xÃ¡c hÆ¡n, nhÆ°ng dÃ¹ng prompt text cÅ©ng á»•n vá»›i GPT-4)
def sufficiency_checker_node(state):
    print("ğŸ§  [CHECKER]: Äang kiá»ƒm tra Ä‘á»™ Ä‘áº§y Ä‘á»§ cá»§a thÃ´ng tin...")
    
    query = state.get("standalone_query", state["query"])
    docs = state.get("retrieved_docs", [])
    chat_history = state.get("chat_history", "")
    
    # Náº¿u khÃ´ng tÃ¬m tháº¥y vÄƒn báº£n nÃ o -> NO_LAW
    if not docs:
        return {"check_status": "NO_LAW"}

    # Táº¡o context tá»« vÄƒn báº£n tÃ¬m Ä‘Æ°á»£c
    context_text = "\n\n".join([f"VÄƒn báº£n: {d['source']}\nNá»™i dung: {d['content']}" for d in docs])

    # --- PROMPT ÄÆ¯á»¢C NÃ‚NG Cáº¤P ("KHÃ“ TÃNH" HÆ N) ---
    checker_prompt = PromptTemplate(
        template="""Báº¡n lÃ  má»™t Tháº©m phÃ¡n cáº¥p cao, cá»±c ká»³ ká»¹ tÃ­nh. Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  Ä‘Ã¡nh giÃ¡ xem thÃ´ng tin hiá»‡n táº¡i ÄÃƒ Äá»¦ Ä‘á»ƒ Ä‘Æ°a ra phÃ¡n quyáº¿t (cÃ¢u tráº£ lá»i) chÃ­nh xÃ¡c cho ngÆ°á»i dÃ¹ng hay chÆ°a.

        1. CÃ‚U Há»I Cá»¦A NGÆ¯á»œI DÃ™NG: "{query}"
        
        2. Lá»ŠCH Sá»¬ TRÃ’ CHUYá»†N (Context):
        {chat_history}

        3. VÄ‚N Báº¢N PHÃP LUáº¬T TÃŒM ÄÆ¯á»¢C:
        {context}

        --- TIÃŠU CHÃ ÄÃNH GIÃ (QUAN TRá»ŒNG) ---
        
        TRÆ¯á»œNG Há»¢P 1: MISSING_INFO (Thiáº¿u thÃ´ng tin chi tiáº¿t)
        - Náº¿u vÄƒn báº£n luáº­t quy Ä‘á»‹nh nhiá»u khung hÃ¬nh pháº¡t khÃ¡c nhau dá»±a trÃªn cÃ¡c yáº¿u tá»‘ Ä‘á»‹nh lÆ°á»£ng (VÃ­ dá»¥: giÃ¡ trá»‹ tÃ i sáº£n, tá»· lá»‡ thÆ°Æ¡ng táº­t, cÃ³ tá»• chá»©c hay khÃ´ng...).
        - VÃ€ ngÆ°á»i dÃ¹ng CHÆ¯A cung cáº¥p cÃ¡c con sá»‘/chi tiáº¿t Ä‘Ã³ trong cÃ¢u há»i hoáº·c lá»‹ch sá»­ chat.
        - VÃ­ dá»¥: Há»i "Trá»™m cáº¯p bá»‹ pháº¡t bao nhiÃªu nÄƒm?" -> Luáº­t cÃ³ khung 6 thÃ¡ng-3 nÄƒm, 2-7 nÄƒm, 7-15 nÄƒm tÃ¹y sá»‘ tiá»n -> NgÆ°á»i dÃ¹ng chÆ°a nÃ³i sá»‘ tiá»n -> MISSING_INFO.
        
        TRÆ¯á»œNG Há»¢P 2: SUFFICIENT (Äá»§ thÃ´ng tin)
        - Náº¿u cÃ¢u há»i chá»‰ mang tÃ­nh Ä‘á»‹nh nghÄ©a, khÃ¡i niá»‡m (VD: "Tháº¿ nÃ o lÃ  ly hÃ´n?").
        - HOáº¶C ngÆ°á»i dÃ¹ng ÄÃƒ cung cáº¥p Ä‘á»§ tÃ¬nh tiáº¿t khá»›p vá»›i má»™t khoáº£n cá»¥ thá»ƒ trong luáº­t.
        - HOáº¶C luáº­t chá»‰ cÃ³ 1 má»©c pháº¡t duy nháº¥t khÃ´ng phá»¥ thuá»™c Ä‘iá»u kiá»‡n.
        
        TRÆ¯á»œNG Há»¢P 3: NO_LAW (Sai luáº­t/KhÃ´ng liÃªn quan)
        - VÄƒn báº£n tÃ¬m Ä‘Æ°á»£c hoÃ n toÃ n khÃ´ng liÃªn quan Ä‘áº¿n cÃ¢u há»i.

        --- YÃŠU Cáº¦U Äáº¦U RA (JSON) ---
        Chá»‰ tráº£ vá» JSON duy nháº¥t, khÃ´ng giáº£i thÃ­ch thÃªm:
        {{
            "status": "SUFFICIENT" | "MISSING_INFO" | "NO_LAW",
            "reason": "Giáº£i thÃ­ch ngáº¯n gá»n táº¡i sao (VÃ­ dá»¥: Cáº§n biáº¿t giÃ¡ trá»‹ tÃ i sáº£n Ä‘á»ƒ xÃ¡c Ä‘á»‹nh khung hÃ¬nh pháº¡t)"
        }}
        """,
        input_variables=["query", "chat_history", "context"]
    )

    chain = checker_prompt | llm | JsonOutputParser()

    try:
        result = chain.invoke({
            "query": query,
            "chat_history": chat_history, 
            "context": context_text
        })
        
        status = result.get("status", "NO_LAW")
        reason = result.get("reason", "")
        
        print(f"   -> ÄÃ¡nh giÃ¡: {status} ({reason})")
        
        return {"check_status": status}
        
    except Exception as e:
        print(f"âš ï¸ Lá»—i Checker: {e}")
        # Máº·c Ä‘á»‹nh cho lÃ  Ä‘á»§ Ä‘á»ƒ Writer xá»­ lÃ½ náº¿u lá»—i
        return {"check_status": "SUFFICIENT"}