"""
Contextualization node for Agentic Legal RAG.

Handles:
- Standalone query rewriting
- Clarification merging
"""

from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

from app.core.clients import get_llm
from app.services.law_agent.state import LawAgentState


def contextualize_node(state: LawAgentState) -> LawAgentState:

    state.node_trace.append("contextualize")

    query = state.query.strip()
    
    # ğŸ§¹ FIRST: Detect law context and extract it BEFORE cleaning the query
    # This preserves the law context in state for later use
    has_law_context = "Ngá»¯ cáº£nh luáº­t:" in query or "Ná»™i dung:" in query
    state.has_law_context = has_law_context
    
    # Extract and store law context for writer/fallback nodes
    if has_law_context:
        if "Ngá»¯ cáº£nh luáº­t:" in query:
            parts = query.split("Ngá»¯ cáº£nh luáº­t:", 1)
            if len(parts) > 1:
                # Get law context up to the next major section
                context_part = parts[1].split("Lá»‹ch sá»­ chat:")[0].split("CÃ¢u há»i")[0]
                state.law_context = "Ngá»¯ cáº£nh luáº­t:" + context_part.strip()
    
    # Now extract the actual question from the combined prompt
    # Handle both law-detail and general formats
    
    # For law-detail format: extract from "CÃ¢u há»i hiá»‡n táº¡i:" or "CÃ¢u há»i:"
    if "CÃ¢u há»i hiá»‡n táº¡i:" in query:
        parts = query.split("CÃ¢u há»i hiá»‡n táº¡i:", 1)
        pure_query = parts[1].split("\n")[0].strip() if len(parts) > 1 else ""
    elif "CÃ¢u há»i:" in query:
        parts = query.split("CÃ¢u há»i:", 1)
        pure_query = parts[1].split("\n")[0].strip() if len(parts) > 1 else ""
    else:
        # Fallback: clean query by removing "Dá»±a trÃªn vÄƒn báº£n..." section
        pure_query = query.split("Dá»±a trÃªn vÄƒn báº£n")[0].strip()
        if not pure_query:
            pure_query = query.split("\n")[0].strip()
    
    # If still empty, use full query
    if not pure_query:
        pure_query = query
    
    # Update state.query with cleaned version so all downstream nodes get clean query
    state.query = pure_query
    
    chat_history = state.chat_history or ""

    # If there is chat history, rewrite as standalone
    if chat_history:

        llm = get_llm()

        prompt = PromptTemplate(
            template="""
Dá»±a trÃªn lá»‹ch sá»­ há»™i thoáº¡i dÆ°á»›i Ä‘Ã¢y,
hÃ£y viáº¿t láº¡i cÃ¢u há»i cuá»‘i cÃ¹ng cá»§a ngÆ°á»i dÃ¹ng
thÃ nh má»™t cÃ¢u há»i phÃ¡p lÃ½ Ä‘áº§y Ä‘á»§, rÃµ nghÄ©a.

Lá»‹ch sá»­:
{chat_history}

CÃ¢u há»i má»›i:
{query}

CÃ¢u há»i Ä‘áº§y Ä‘á»§:
""",
            input_variables=["chat_history", "query"],
        )

        chain = prompt | llm | StrOutputParser()

        try:
            standalone = chain.invoke({
                "chat_history": chat_history,
                "query": pure_query  # Use cleaned query for rewrite
            })

            # Clean the rewritten query again
            pure_standalone = standalone.split("Dá»±a trÃªn vÄƒn báº£n")[0].strip()
            if not pure_standalone:
                pure_standalone = standalone.split("\n")[0].strip()
            
            if not pure_standalone:
                pure_standalone = standalone.strip()
            
            state.standalone_query = pure_standalone
            return state

        except Exception:
            state.standalone_query = pure_query
            return state

    # No history â†’ use cleaned query as standalone
    state.standalone_query = pure_query
    return state
